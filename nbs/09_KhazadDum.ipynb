{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "output-file: KhazadDum.html\n",
    "title: Khazad Dum - Delving for Data with a Text2SQL Agent\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d97b67",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between; align-items: center;\">\n",
    "  <span>ðŸ“… 30/11/2025</span>\n",
    "    <p align=\"right\">\n",
    "    <a href=\"https://colab.research.google.com/github/tripathysagar/sagaTrip/blob/main/nbs/09_KhazadDum.ipynb\" target=\"_blank\">\n",
    "        <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "    </a>\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d2010f",
   "metadata": {},
   "source": [
    "\n",
    "In Tolkien's Middle-earth, the dwarves of Khazad Dum delved deep into the mountains. They were mining mithrilâ€”the most precious metal in the realm. My text2sql agent borrows that name because it does something similar: it digs into your database and surfaces the insights you're looking for, no pickaxe (or SQL expertise) required. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114340f4",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## **The Problem**\n",
    "\n",
    "Writing SQL is a powerful skill, but doing it effectively requires deep knowledge of the underlying database structure. Which table holds customer emailsâ€”`users`, `customers`, or `contacts`? What's the exact column name for order dates? These questions slow you down and create a barrier, especially for those who aren't living in the database day-to-day.\n",
    "\n",
    "What if you could just *ask* for the data you need in plain English? That's where LLMs come inâ€”their flexibility lets us bridge the gap between natural language and structured queries.\n",
    "I am running the experimentation in [spider 2.0 Snowflake DB](https://github.com/xlang-ai/Spider2/tree/main/spider2-snow)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a37dffc",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## How Khazad Dum Works\n",
    "\n",
    "Khazad Dum is built on a simple but flexible stack:\n",
    "- **lisette** handles LLM tool-calling\n",
    "- **FastHTML** powers a lightweight chat interface\n",
    "- **SQLite** stores conversation history\n",
    "\n",
    "When you ask a question, the agent gets to work: it inspects the database schema, translates your request into SQL, and runs the query. If something goes wrong â€” a typo in a table name, a syntax hiccup â€” it doesn't give up. Like the dwarves who kept mining through hard rock, the agent takes the error, learns from it, and tries again with a corrected query.\n",
    "\n",
    "The database layer follows a clean interface pattern: connect, check if the connection is alive, extract metadata, and execute queries. Swapping from SQLite to Oracle or Snowflake just means implementing this same interface for the new dialect â€” the rest of the agent stays untouched.\n",
    "\n",
    "**Metadata Building** Before the agent can write accurate SQL, it needs to understand the lay of the land. When Khazad Dum connects to a database, it automatically extracts metadata â€” table names, column names, data types, and relationships. Think of it as the agent drawing a map of the mines before it starts digging. This schema knowledge is what allows it to turn your plain English question into a query that actually runs.\n",
    "\n",
    "\n",
    "Complete code is available on [Khazad Dum GitHub](https://github.com/tripathysagar/KhazadDum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f875d8fd",
   "metadata": {},
   "source": [
    "\n",
    "## A Quick Example\n",
    "\n",
    "> **User:** *\"Which airport has the most departures?\"*\n",
    "\n",
    "Khazad Dum gets to work. Its first attempt:\n",
    "\n",
    "```sql\n",
    "SELECT GET(PARSE_JSON(\"airport_name\"), 'en')::VARCHAR AS \"airport_name\", \n",
    "       COUNT(*) AS \"departure_count\"\n",
    "FROM AIRLINES.AIRLINES.\"FLIGHTS\"\n",
    "GROUP BY \"departure_airport\"\n",
    "ORDER BY \"departure_count\" DESC\n",
    "LIMIT 1\n",
    "```\n",
    "\n",
    "**Error:** `invalid identifier '\"airport_name\"'`\n",
    "\n",
    "The agent reads the error, realizes `airport_name` lives in a different table, and retries with a join:\n",
    "\n",
    "```sql\n",
    "SELECT GET(PARSE_JSON(\"airport_name\"), 'en')::VARCHAR AS \"airport_name\", \n",
    "       COUNT(*) AS \"departure_count\"\n",
    "FROM AIRLINES.AIRLINES.\"FLIGHTS\"\n",
    "JOIN AIRLINES.AIRLINES.\"AIRPORTS_DATA\" \n",
    "  ON \"FLIGHTS\".\"departure_airport\" = \"AIRPORTS_DATA\".\"airport_code\"\n",
    "GROUP BY \"airport_name\"\n",
    "ORDER BY \"departure_count\" DESC\n",
    "LIMIT 1\n",
    "```\n",
    "\n",
    "**Result:** Domodedovo International Airport â€” 3,217 departures.\n",
    "\n",
    "One plain English question, one self-correction, one answer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906c9290",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## What I Learned\n",
    "\n",
    "**Small models can punch above their weight.** I was surprised how well a modest LLM like `gpt-4o-mini` handled the task â€” running on a Mac, it solved queries effectively. The key was clear tool definitions: when the interface is well-defined, the model knows exactly what to do and can self-correct on failures.\n",
    "\n",
    "**Metadata is crucial â€” and worth caching.** Extracting column names and data types was straightforward, but inferring foreign key relationships required prompting the LLM. That's a costly operation, so I added caching to avoid repeating it. Lesson learned: invest in good metadata upfront, then reuse it.\n",
    "\n",
    "**Simple tools make fast iteration possible.** Both lisette and FastHTML stayed out of my way, which meant I could focus on what mattered: finding the right prompts. And that's where the real work was â€” iterating quickly on prompts until the agent behaved the way I wanted.\n",
    "\n",
    "**Model fails to answer for ambiguous questions.** As question get complex the model does not perform well and generalize."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386b35a0",
   "metadata": {},
   "source": [
    "## What's Next\n",
    "\n",
    "Khazad Dum already supports multi-turn conversations â€” you can ask follow-up questions and refine your queries naturally. But there's more mining to do:\n",
    "\n",
    "**More databases.** The current interface works with SQLite, Oracle, and Snowflake, but I'd like to extend support to Postgres, MySQL, and beyond. The clean interface pattern should make this straightforward.\n",
    "\n",
    "**Recursive Language Models.** I'm exploring recursive approaches where the agent can break complex questions into smaller sub-queries, solve them step by step, and combine the results. Think of it as the dwarves digging multiple tunnels that eventually connect.\n",
    "\n",
    "The mines of Khazad Dum go deep â€” there's plenty more mithril to uncover."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcc6f50",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
