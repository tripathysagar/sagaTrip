{
 "cells": [
  {
   "cell_type": "raw",
   "id": "e626c0ad",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Small LLMs Can't Add—But They Can Learn to Ask\"\n",
    "description: \"A Small LM  can't add 6-digit numbers—but it can learn to ask a calculator to do it, and generalize to arbitrary numbers.\"\n",
    "output-file: llm-arithmetic-experiments.html\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6c3c48",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "I wanted to test a hypothesis: can a small language model master integer addition through training? Given two n-digit integers, can it learn to handle carries and digit alignment? I chose the base model(not an Instruct one) as it is mostly trained on predicting next token rather than following instruction and solving complex task. I considered **SmolLM2-135M**, for this experiment as it is small and efficient enough to run many experiments on colab T4. \n",
    "\n",
    "**Spoiler alert**: pure chain-of-thought training hit a hard ceiling, but tool use opened a surprising path forward.\n",
    "\n",
    "**Notebooks** \n",
    "\n",
    "| Description | Link |\n",
    "|-------------|------|\n",
    "| COT training experiment | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tripathysagar/llm-arithmetic-experiments/blob/main/add_cot_exp.ipynb) |\n",
    "| Tool use SFT experiment | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tripathysagar/llm-arithmetic-experiments/blob/main/add_tool_exp.ipynb) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594ee40a",
   "metadata": {},
   "source": [
    "## Chain-Of-Thought Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e0be77",
   "metadata": {},
   "source": [
    "### Data format "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a61631e",
   "metadata": {},
   "source": [
    "As our experiment is small enough we can generate synthetic data for the addition which will give us more control. The data contain following structure:\n",
    "\n",
    "1. padding the shorter number with leading zeros\n",
    "1. init the `carry = 0`\n",
    "1. perform adding from the rightmost part of the numbers (least significant digit) with previous carry\n",
    "1. then extract the result digit and carry \n",
    "1. repeat prev step for all the digits in the numbers\n",
    "1. if final carry > 0 then it becomes the leading digit\n",
    "\n",
    "A simple COT for addition of 1 with 99 is brokendown to `01 + 99; col1: 1+9+0=10, write 0 carry 1; col2: 0+9+1=10, write 0 carry 1; final carry 1; answer=100`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60deb1b",
   "metadata": {},
   "source": [
    "### Training Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31db1f7a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "I used **SmolLM2-135M** (base model) with the following configuration:\n",
    "- Epochs: 5\n",
    "- Batch size: 32\n",
    "- Learning rate: 5e-4\n",
    "\n",
    "For data, I generated synthetic addition problems across digit ranges:\n",
    "- 2-digit: 500 train / 50 val / 50 test\n",
    "- 3-digit: 6000 train / 550 val / 550 test\n",
    "\n",
    "I ran two experiments:\n",
    "1. Train on 1-4 digit combinations, test on 5 digits\n",
    "2. Train on 1-5 digit combinations, test on 6 digits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f843f2d6",
   "metadata": {},
   "source": [
    "### In-range Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75c2205",
   "metadata": {},
   "source": [
    "Within the training digit range, the model achieved near-perfect accuracy. It learned the COT format correctly:\n",
    "\n",
    "```\n",
    "10000 + 999 = 10000+00999, 0+9=9→9c0, 0+9=9→9c0, 0+9=9→9c0, 0+0=0→0c0, 1+0=1→1c0, →10999\n",
    "```\n",
    "\n",
    "The column-by-column reasoning and carry tracking worked flawlessly for problems within the trained range.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f25f044",
   "metadata": {},
   "source": [
    "### Out-of-range Failure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd2ca6d",
   "metadata": {},
   "source": [
    "Testing on numbers beyond the training range revealed a hard ceiling. The model systematically **truncated inputs** to the maximum trained digit length rather than padding leading zeros:\n",
    "\n",
    "```\n",
    "222222 + 22222 = 22222+22222, 2+2=4→4c0, 2+2=4→4c0, 2+2=4→4c0, 2+2=4→4c0, 2+2=4→4c0, →44444\n",
    "```\n",
    "\n",
    "Expected answer: `244444`. The model dropped the leading `2` from `222222`, reducing it to a 5-digit problem it knew how to solve.\n",
    "\n",
    "**Key observation:** The model perfectly memorized the COT pattern but couldn't extend it beyond its training distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8434d03",
   "metadata": {},
   "source": [
    "**What worked:** The model correctly extracted and aligned digits from the input.  \n",
    "**What failed:** Following through on the multi-step addition algorithm.\n",
    "\n",
    "Looking at the failure more carefully: the model did correctly identify both numbers from the input. The breakdown happened at the carry logic, not the parsing. This suggests the model's strength lies in pattern recognition and extraction, not multi-step computation. Meanwhile, a CPU handles arithmetic trivially. So rather than teaching the model to *perform* addition, why not teach it to *extract* the operands and delegate the computation? This is the core idea behind tool use.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f7a277",
   "metadata": {},
   "source": [
    "## Tool Use Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57a0a8e",
   "metadata": {},
   "source": [
    "### Data Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b858483",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_nm = \"HuggingFaceTB/SmolLM2-135M\"\n",
    "tok = AutoTokenizer.from_pretrained(model_nm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f200d21",
   "metadata": {},
   "source": [
    "Instead of the complete tracing of through addition our scope of data now limited. For input: `a + b` will be converted to `<tool>add(a, b)</tool>`. Note: The tokenizer for the model does not have any special token for tool use. So I used raw string rather than expanding the vocab to keep the embedding fixed.\n",
    "\n",
    "To give more entropy in the data, randomly select from the following formats\n",
    "\n",
    "\n",
    "```py\n",
    "formats = [\n",
    "    \"{a} + {b}\",\n",
    "    \"Add: {a}, {b}\",\n",
    "    \"{a} + {b} = \",\n",
    "    \"{a}+{b}=?\",\n",
    "    \"sum of {a} and {b}\",\n",
    "    \"What is {a} + {b}?\",\n",
    "    \"{a} plus {b}\",\n",
    "    \"Calculate {a} + {b}\"\n",
    "]\n",
    "```\n",
    "\n",
    "For prompt/input `'Add: 1, 2'` expects output of `'<tool>add(1, 2)</tool>'`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34839801",
   "metadata": {},
   "source": [
    "### Training Setup\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd83781b",
   "metadata": {},
   "source": [
    "Same base model (**SmolLM2-135M**), with slightly adjusted hyperparameters:\n",
    "- Epochs: 3\n",
    "- Batch size: 16\n",
    "- Learning rate: 2e-4\n",
    "- LR scheduler: cosine\n",
    "\n",
    "For data, I generated addition problems for all digit combinations from 1-7 digits:\n",
    "- Train: ~18,340 examples (also worked with just 2,500)\n",
    "- Validation: ~2,280 examples\n",
    "- Test: ~2,280 examples\n",
    "\n",
    "Out-of-distribution testing used numbers in the 8-11 digit range. I used Hugging Face's **SFTTrainer** for this experiment, which is designed for supervised fine-tuning on instruction-style data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fb6664",
   "metadata": {},
   "source": [
    "### In-range Results\n",
    "\n",
    "The model achieved **100% accuracy** on the in-distribution test set. It learned to extract operands from all prompt formats and emit the correct tool call syntax.\n",
    "\n",
    "### Out-of-range Results\n",
    "\n",
    "Testing on 8-11 digit numbers (well beyond the 1-7 digit training range):\n",
    "\n",
    "| Test Category | Accuracy |\n",
    "|---------------|----------|\n",
    "| both_large (8-11 + 8-11) | 99.3% (894/900) |\n",
    "| small_large (1-7 + 8-11) | 99.6% (2091/2100) |\n",
    "| large_small (8-11 + 1-7) | 99.8% (2096/2100) |\n",
    "\n",
    "Unlike COT, the model generalized **4+ digits beyond its training distribution** with minimal errors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d21c5f",
   "metadata": {},
   "source": [
    "### Surprising Generalizations\n",
    "\n",
    "The model also handled formats not seen in training:\n",
    "\n",
    "| Input | Output |\n",
    "|-------|--------|\n",
    "| `-12345678 + 876888881` | `add(12345678, 876888881)` |\n",
    "| `0.1 + 87654321` | `add(0.1, 87654321)` |\n",
    "| `0.1 + 0.24` | `add(0.1, 0.24)` |\n",
    "\n",
    "It learned to extract number-like tokens, including decimals—though it drops negative signs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e744e2",
   "metadata": {},
   "source": [
    "### Failure Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc97dc4",
   "metadata": {},
   "source": [
    "The few errors that occurred follow a distinct pattern: **digit duplication**. The model adds an extra repeated digit at the end of numbers:\n",
    "\n",
    "\n",
    "\n",
    "| Prompt | Expected | Got |\n",
    "|--------|----------|-----|\n",
    "| `16842957+1773685222=?` | `add(16842957, 1773685222)` | `add(16842957, 17736852222)` |\n",
    "| `sum of 241527736 and 375562333` | `add(241527736, 375562333)` | `add(241527736, 3755623333)` |\n",
    "| `77043+72111115=?` | `add(77043, 72111115)` | `add(77043, 721111115)` |\n",
    "| `3921334444 + 8630895 = ` | `add(3921334444, 8630895)` | `add(39213344444, 8630895)` |\n",
    "\n",
    "\n",
    "\n",
    "Instead, it's an **autoregressive stopping problem**: during generation, when the model sees a sequence like `...222`, it has learned that \"more of the same\" is likely — and occasionally overshoots, emitting one digit too many."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635251dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1773685222 → 10 tokens: ['1', '7', '7', '3', '6', '8', '5', '2', '2', '2']\n",
      "375562333 → 9 tokens: ['3', '7', '5', '5', '6', '2', '3', '3', '3']\n",
      "616497833 → 9 tokens: ['6', '1', '6', '4', '9', '7', '8', '3', '3']\n",
      "72111115 → 8 tokens: ['7', '2', '1', '1', '1', '1', '1', '5']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "failures = ['1773685222', '375562333', '616497833', '72111115'] \n",
    "\n",
    "for num in failures:\n",
    "    tokens = tok.encode(num)\n",
    "    decoded = [tok.decode([t]) for t in tokens]\n",
    "    print(f\"{num} → {len(tokens)} tokens: {decoded}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c809f2d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Notice that failures cluster around numbers with **repeated trailing digits**. The tokenizer encodes each digit separately (no multi-digit tokens), so this isn't a tokenization boundary issue.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee49baaa",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad9d93d",
   "metadata": {},
   "source": [
    "\n",
    "| Approach | In-range | Out-of-range | Failure Mode |\n",
    "|----------|----------|--------------|--------------|\n",
    "| COT | ~100% | 0% generalization | Truncates inputs |\n",
    "| Tool use | 100% | 99%+ | Occasional digit duplication |\n",
    "\n",
    "One can extend the dataset to handle other arithmetic operations—if addition can be learned this easily, multiplication or division likely can too. The model even showed some ability to extract decimals, though edge cases like negative numbers weren't handled correctly. COT requires the model to *perform* arithmetic—tracking carries across variable-length sequences. Tool use only requires the model to *extract and copy* numbers into a fixed format.\n",
    "\n",
    "**Key insight:** by letting the model leverage the CPU for computation rather than teaching complex algorithms. By converting the problem from multi-step reasoning to number extraction, the model generalizes far beyond its training distribution."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
