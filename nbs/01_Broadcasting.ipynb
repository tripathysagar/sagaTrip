{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Broadcasting\n","\n","Goal is to write a blog around broadcasting around pytorch which is backbone of deeplearning.\n","\n","## The Need for Broadcasting\n","\n","1. **Efficiency in Operations**: Without broadcasting, you'd need to manually resize arrays to perform operations between differently shaped tensors. This would require writing explicit loops or creating temporary copies of data, both of which are inefficient.\n","\n","2. **Code Readability**: Imagine having to write nested loops every time you want to add a scalar to each element in a matrix, or add corresponding elements of arrays with different dimensions. Your code would become cluttered and harder to understand.\n","\n","3. **Memory Optimization**: Broadcasting allows operations without actually duplicating the data in memory. This is crucial when working with large tensors in deep learning."]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import torch \n","\n","A = torch.randn((256, 128))\n","B = torch.randn((128, 64))"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["#| hide\n","ar, ac = A.shape\n","br, bc = B.shape"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Using loops\n","Ofcourse we can simply do A.matmul(B) but we want to learn broadcasting. \n","Lets start by a traditional approach i.e. loops.\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/plain":["torch.Size([256, 64])"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["#| hide\n","C = torch.zeros((ar, bc))\n","C.shape"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["#| hide\n","for i in range(ar):\n","    for j in range(bc):\n","        temp = 0.\n","        for k in range(ac):\n","            temp += A[i,k]* B[k, j]\n","        C[i,j] = temp"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def mul1(a, b):\n","    ar, ac = a.shape\n","    br, bc = b.shape\n","    c = torch.zeros((ar, bc))\n","\n","    for i in range(ar):\n","        for j in range(bc):\n","            temp = 0.\n","            for k in range(ac):\n","                temp += a[i,k]* b[k, j]\n","            c[i,j] = temp\n","    \n","    return c"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n","Wall time: 7.63 µs\n"]}],"source":["%time\n","c = mul1(A, B)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Removing innermost loop"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["(torch.Size([128]), torch.Size([128]))"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["#| hide\n","A[0,:].shape, B[:,0].shape"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["torch.Size([128])"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["#| hide\n","(A[0,:]*B[:,0]).shape"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["def mul2(a, b):\n","    ar, ac = a.shape\n","    br, bc = b.shape\n","    c = torch.zeros((ar, bc))\n","\n","    for i in range(ar):\n","        for j in range(bc):\n","            \n","            c[i,j] = torch.sum(a[i,:]*b[:,j])\n","    \n","    return c"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["assert torch.allclose(c, mul2(A, B),  rtol=1e-2) ## for checking if the result are same"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 6 µs, sys: 0 ns, total: 6 µs\n","Wall time: 13.6 µs\n"]}],"source":["%time\n","_ = mul2(A, B)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["**Rules for broadcasting**<br>\n","PyTorch compares the shapes element-wise, starting from the rightmost dimension\n","Dimensions are compatible when:\n","- They are equal, or\n","- One of them is 1 (which gets \"stretched\"), or\n","- One doesn't exist (which gets \"added\" as a dimension of size 1)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/plain":["(torch.Size([3]), torch.Size([]))"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["T = torch.randn((3))\n","S = torch.tensor(5)\n","\n","T.shape, S.shape"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["#| hide\n","def show():\n","    import graphviz\n","\n","    # Create the directed graph\n","    flow = graphviz.Digraph('broadcasting_flow', comment='Broadcasting Flow Diagram')\n","\n","    # Node definitions\n","    flow.attr('node', shape='box', style='filled', color='lightblue')\n","\n","    # Start with input tensors\n","    flow.node('input1', 'Tensor T\\nShape: (3)')\n","    flow.node('input2', 'Scalar S\\nShape: ()')\n","\n","    # Broadcasting process nodes\n","    flow.node('compare', 'Compare shapes\\nright-to-left')\n","    flow.node('expand', 'Virtual expansion\\nof scalar S')\n","    flow.node('virtual', 'Virtual tensor\\nS repeated 3 times\\nShape: (3)')\n","    flow.node('operation', 'Element-wise\\nmultiplication')\n","    flow.node('result', 'Result tensor\\nShape: (3)')\n","\n","    # Edges showing the flow\n","    flow.edge('input1', 'compare')\n","    flow.edge('input2', 'compare')\n","    flow.edge('compare', 'expand')\n","    flow.edge('expand', 'virtual')\n","    flow.edge('input1', 'operation')\n","    flow.edge('virtual', 'operation')\n","    flow.edge('operation', 'result')\n","    flow.render('data/broadcasting_flow', format='png', cleanup=True)\n","#show()\n"]},{"cell_type":"markdown","metadata":{},"source":["![Flow Diagram](data/broadcasting_flow.png)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/plain":["torch.Size([64])"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["#| hide\n","(A[1] @ B).shape"]},{"cell_type":"markdown","metadata":{},"source":["## With only one loop"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["def mul3(a, b):\n","    ar, ac = a.shape\n","    br, bc = b.shape\n","    c = torch.zeros((ar, bc))\n","\n","    for i in range(ar):\n","        c[i] = A[i] @ B  # dim[128] * dim[128,64]\n","    return c"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["assert torch.allclose(c, mul3(A, B),  rtol=1e-2) "]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n","Wall time: 8.34 µs\n"]}],"source":["%time\n","_ = mul3(A, B)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## matrix multiplication\n","best and fastest"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n","Wall time: 7.39 µs\n"]}],"source":["%time\n","_ = A @ B"]}],"metadata":{"kernelspec":{"display_name":"python3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":4}
